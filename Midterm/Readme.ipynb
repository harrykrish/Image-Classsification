{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification of Buildings (Binary Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to use a convolutional neural network to identify objects in a image from Google maps. The objective is to classify different objects like Building, Road, Trees etc.\n",
    "\n",
    "This will be useful to create shape files of locations. This project can be further developed to pass the image of a location which has many objects and the network can be trained to identify various kinds of objects and create .shp files from them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps involved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reading an image\n",
    "* Converting it to the required size\n",
    "* Passing the image through a convolutional neural network to determine accruacy with which the building is identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READING THE IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The images are classified into testing and training data sets which are used to train the model\n",
    "* These images are named as Buildings if the image has a building object\n",
    "* The images are saved in a numpy array\n",
    "* There are two numpy arrays. One that contains the image and the other contains the label associated with the image ('Building' is given a value 1 and 'Not a building' as 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CONVERTING IMAGE TO THE REQUIRED SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The opencv package is used to read and convert the image to the required size so that it can be fed to the neural network\n",
    "* In our case the image is converted to 128x128x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVOLUTIONAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Framework Adpoted : TensorFlow\n",
    "* GPU : AWS Bitfusion Ubuntu 14 TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The image that has been converted to the desired size is fed to the convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional and Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input Layer - Dimensions - (252, 128, 128, 3)\n",
    "* Convolutional Layer 1 - (252, 128, 128, 32)\n",
    "* Max Pooling 1 - (252, 64, 64, 32)\n",
    "* Convolutional Layer 2 - (252, 64, 64, 16)\n",
    "* Max pooling 2 - (252, 32, 32, 16)\n",
    "* Convolutional Layer 3 - (252, 128, 128, 4)\n",
    "* Max Pooling 3 - (252, 64, 64, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Once the convolutional layers are applied, the output is flattened and dense layers are applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Flattening - (252, 16384)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layers are applied\n",
    "* Dense Layer 1 - (252, 256)\n",
    "* Dense Layer 2 - (252, 32)\n",
    "* Dense Layer 3 - (252, 16)\n",
    "* Dense Layer 4 - (252, 8)\n",
    "* Dense Layer 5 - (252, 4)\n",
    "* Dense Layer 6 - (252, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Accuracy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy achieved is <b>79.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multi class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification of Roads, Trees and Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"Accuracy2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy achieved is <b>64.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
